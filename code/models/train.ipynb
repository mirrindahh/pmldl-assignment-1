{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomRotation(10),     \n",
    "        transforms.RandomHorizontalFlip(),  \n",
    "        transforms.Resize(224),             \n",
    "        transforms.CenterCrop(224),         \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],\n",
    "                         [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(root=\"../datasets/cats-and-dogs/train\", transform=train_transform)\n",
    "test_data = datasets.ImageFolder(root=\"../datasets/cats-and-dogs/test\", transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: cat, index: 0\n",
      "Label: dog, index: 1\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(train_data.classes):\n",
    "    print(f\"Label: {label}, index: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(16 * 54 * 54, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 20)\n",
    "        self.fc4 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 16 * 54 * 54)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = F.relu(self.fc3(X))\n",
    "        X = self.fc4(X)\n",
    "        \n",
    "        return F.log_softmax(X, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = ConvolutionalNetwork()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch: 1 loss: 0.5147902965545654 batch: 200 accuracy:  56.938%\n",
      "TRAIN: epoch: 1 loss: 0.6590794324874878 batch: 400 accuracy:  59.438%\n",
      "TRAIN: epoch: 1 loss: 0.4818272590637207 batch: 600 accuracy:  60.729%\n",
      "TRAIN: epoch: 1 loss: 0.6689613461494446 batch: 800 accuracy:  61.953%\n",
      "TRAIN: epoch: 1 loss: 0.531286895275116 batch: 1000 accuracy:  62.688%\n",
      "TRAIN: epoch: 1 loss: 0.59315025806427 batch: 1200 accuracy:  63.625%\n",
      "TRAIN: epoch: 1 loss: 0.43596112728118896 batch: 1400 accuracy:  64.696%\n",
      "TRAIN: epoch: 1 loss: 0.7025898098945618 batch: 1600 accuracy:  65.359%\n",
      "TRAIN: epoch: 1 loss: 0.43715700507164 batch: 1800 accuracy:  66.056%\n",
      "TRAIN: epoch: 1 loss: 0.7208001613616943 batch: 2000 accuracy:  66.675%\n",
      "TRAIN: epoch: 1 loss: 0.5569039583206177 batch: 2200 accuracy:  67.188%\n",
      "TRAIN: epoch: 1 loss: 0.46903637051582336 batch: 2400 accuracy:  67.651%\n",
      "TRAIN: epoch: 1 loss: 0.4140457212924957 batch: 2600 accuracy:  68.149%\n",
      "TRAIN: epoch: 1 loss: 0.4694763422012329 batch: 2800 accuracy:  68.522%\n",
      "TEST: epoch: 1 loss: 0.2827723026275635 batch: 50 accuracy:  83.750%\n",
      "TEST: epoch: 1 loss: 0.3729497790336609 batch: 100 accuracy:  83.750%\n",
      "TEST: epoch: 1 loss: 0.3133392930030823 batch: 150 accuracy:  82.667%\n",
      "TEST: epoch: 1 loss: 0.7185328602790833 batch: 200 accuracy:  78.562%\n",
      "TEST: epoch: 1 loss: 0.6782515645027161 batch: 250 accuracy:  75.250%\n",
      "TEST: epoch: 1 loss: 0.5715590119361877 batch: 300 accuracy:  73.250%\n",
      "TRAIN: epoch: 2 loss: 0.5455083847045898 batch: 200 accuracy:  74.125%\n",
      "TRAIN: epoch: 2 loss: 0.3427307903766632 batch: 400 accuracy:  75.250%\n",
      "TRAIN: epoch: 2 loss: 0.5911321640014648 batch: 600 accuracy:  75.104%\n",
      "TRAIN: epoch: 2 loss: 0.5236721038818359 batch: 800 accuracy:  75.781%\n",
      "TRAIN: epoch: 2 loss: 0.6195803880691528 batch: 1000 accuracy:  75.963%\n",
      "TRAIN: epoch: 2 loss: 0.5018994808197021 batch: 1200 accuracy:  75.781%\n",
      "TRAIN: epoch: 2 loss: 0.4277783930301666 batch: 1400 accuracy:  75.955%\n",
      "TRAIN: epoch: 2 loss: 0.193511962890625 batch: 1600 accuracy:  76.086%\n",
      "TRAIN: epoch: 2 loss: 0.5598113536834717 batch: 1800 accuracy:  76.271%\n",
      "TRAIN: epoch: 2 loss: 0.613674521446228 batch: 2000 accuracy:  76.131%\n",
      "TRAIN: epoch: 2 loss: 0.7419936656951904 batch: 2200 accuracy:  76.188%\n",
      "TRAIN: epoch: 2 loss: 0.33984383940696716 batch: 2400 accuracy:  76.276%\n",
      "TRAIN: epoch: 2 loss: 0.5327383875846863 batch: 2600 accuracy:  76.337%\n",
      "TRAIN: epoch: 2 loss: 0.6739825010299683 batch: 2800 accuracy:  76.379%\n",
      "TEST: epoch: 2 loss: 0.18799260258674622 batch: 50 accuracy:  89.000%\n",
      "TEST: epoch: 2 loss: 0.36733925342559814 batch: 100 accuracy:  88.500%\n",
      "TEST: epoch: 2 loss: 0.272962749004364 batch: 150 accuracy:  88.750%\n",
      "TEST: epoch: 2 loss: 0.5300604701042175 batch: 200 accuracy:  83.875%\n",
      "TEST: epoch: 2 loss: 0.8926554918289185 batch: 250 accuracy:  79.750%\n",
      "TEST: epoch: 2 loss: 0.5229856967926025 batch: 300 accuracy:  77.458%\n",
      "TRAIN: epoch: 3 loss: 1.1961219310760498 batch: 200 accuracy:  77.625%\n",
      "TRAIN: epoch: 3 loss: 0.37926197052001953 batch: 400 accuracy:  78.125%\n",
      "TRAIN: epoch: 3 loss: 0.5168243050575256 batch: 600 accuracy:  78.500%\n",
      "TRAIN: epoch: 3 loss: 0.49385565519332886 batch: 800 accuracy:  78.453%\n",
      "TRAIN: epoch: 3 loss: 0.22636845707893372 batch: 1000 accuracy:  78.325%\n",
      "TRAIN: epoch: 3 loss: 0.6779004335403442 batch: 1200 accuracy:  78.708%\n",
      "TRAIN: epoch: 3 loss: 0.4232236444950104 batch: 1400 accuracy:  78.938%\n",
      "TRAIN: epoch: 3 loss: 0.401105135679245 batch: 1600 accuracy:  78.781%\n",
      "TRAIN: epoch: 3 loss: 0.7370246648788452 batch: 1800 accuracy:  78.757%\n",
      "TRAIN: epoch: 3 loss: 0.5935763120651245 batch: 2000 accuracy:  78.737%\n",
      "TRAIN: epoch: 3 loss: 0.8911645412445068 batch: 2200 accuracy:  78.903%\n",
      "TRAIN: epoch: 3 loss: 0.916724443435669 batch: 2400 accuracy:  79.193%\n",
      "TRAIN: epoch: 3 loss: 0.3424931764602661 batch: 2600 accuracy:  79.183%\n",
      "TRAIN: epoch: 3 loss: 0.7225573062896729 batch: 2800 accuracy:  79.009%\n",
      "TEST: epoch: 3 loss: 0.28229859471321106 batch: 50 accuracy:  83.750%\n",
      "TEST: epoch: 3 loss: 0.3488997220993042 batch: 100 accuracy:  84.750%\n",
      "TEST: epoch: 3 loss: 0.26666831970214844 batch: 150 accuracy:  84.500%\n",
      "TEST: epoch: 3 loss: 0.7566356062889099 batch: 200 accuracy:  82.000%\n",
      "TEST: epoch: 3 loss: 0.6524239778518677 batch: 250 accuracy:  80.600%\n",
      "TEST: epoch: 3 loss: 0.42942920327186584 batch: 300 accuracy:  79.667%\n",
      "TRAIN: epoch: 4 loss: 0.6383426189422607 batch: 200 accuracy:  81.438%\n",
      "TRAIN: epoch: 4 loss: 0.24209052324295044 batch: 400 accuracy:  81.812%\n",
      "TRAIN: epoch: 4 loss: 0.396977037191391 batch: 600 accuracy:  81.146%\n",
      "TRAIN: epoch: 4 loss: 0.22619105875492096 batch: 800 accuracy:  80.938%\n",
      "TRAIN: epoch: 4 loss: 0.4153054356575012 batch: 1000 accuracy:  80.812%\n",
      "TRAIN: epoch: 4 loss: 0.5028054714202881 batch: 1200 accuracy:  80.656%\n",
      "TRAIN: epoch: 4 loss: 0.2966775596141815 batch: 1400 accuracy:  80.670%\n",
      "TRAIN: epoch: 4 loss: 0.27252185344696045 batch: 1600 accuracy:  80.906%\n",
      "TRAIN: epoch: 4 loss: 0.6013477444648743 batch: 1800 accuracy:  80.854%\n",
      "TRAIN: epoch: 4 loss: 0.10494460165500641 batch: 2000 accuracy:  80.769%\n",
      "TRAIN: epoch: 4 loss: 0.3217506408691406 batch: 2200 accuracy:  80.881%\n",
      "TRAIN: epoch: 4 loss: 0.3126172125339508 batch: 2400 accuracy:  80.823%\n",
      "TRAIN: epoch: 4 loss: 0.4199337065219879 batch: 2600 accuracy:  80.875%\n",
      "TRAIN: epoch: 4 loss: 0.5275400280952454 batch: 2800 accuracy:  80.902%\n",
      "TEST: epoch: 4 loss: 0.09670166671276093 batch: 50 accuracy:  85.750%\n",
      "TEST: epoch: 4 loss: 0.2654397785663605 batch: 100 accuracy:  85.500%\n",
      "TEST: epoch: 4 loss: 0.14539414644241333 batch: 150 accuracy:  85.333%\n",
      "TEST: epoch: 4 loss: 0.7574214935302734 batch: 200 accuracy:  83.000%\n",
      "TEST: epoch: 4 loss: 0.8382458090782166 batch: 250 accuracy:  81.000%\n",
      "TEST: epoch: 4 loss: 0.44726771116256714 batch: 300 accuracy:  80.167%\n",
      "TRAIN: epoch: 5 loss: 0.28662702441215515 batch: 200 accuracy:  83.500%\n",
      "TRAIN: epoch: 5 loss: 0.2681192457675934 batch: 400 accuracy:  82.875%\n",
      "TRAIN: epoch: 5 loss: 0.216677725315094 batch: 600 accuracy:  82.854%\n",
      "TRAIN: epoch: 5 loss: 0.42266297340393066 batch: 800 accuracy:  82.828%\n",
      "TRAIN: epoch: 5 loss: 0.3640150725841522 batch: 1000 accuracy:  82.350%\n",
      "TRAIN: epoch: 5 loss: 0.1549166589975357 batch: 1200 accuracy:  82.000%\n",
      "TRAIN: epoch: 5 loss: 1.0036299228668213 batch: 1400 accuracy:  81.938%\n",
      "TRAIN: epoch: 5 loss: 0.6159014105796814 batch: 1600 accuracy:  81.820%\n",
      "TRAIN: epoch: 5 loss: 0.3617039918899536 batch: 1800 accuracy:  81.979%\n",
      "TRAIN: epoch: 5 loss: 0.30375850200653076 batch: 2000 accuracy:  82.037%\n",
      "TRAIN: epoch: 5 loss: 0.37803471088409424 batch: 2200 accuracy:  81.983%\n",
      "TRAIN: epoch: 5 loss: 0.2965126931667328 batch: 2400 accuracy:  81.953%\n",
      "TRAIN: epoch: 5 loss: 0.5681209564208984 batch: 2600 accuracy:  81.923%\n",
      "TRAIN: epoch: 5 loss: 0.23395760357379913 batch: 2800 accuracy:  81.817%\n",
      "TEST: epoch: 5 loss: 0.16021060943603516 batch: 50 accuracy:  85.500%\n",
      "TEST: epoch: 5 loss: 0.325283408164978 batch: 100 accuracy:  85.625%\n",
      "TEST: epoch: 5 loss: 0.18662622570991516 batch: 150 accuracy:  85.167%\n",
      "TEST: epoch: 5 loss: 0.7722673416137695 batch: 200 accuracy:  83.500%\n",
      "TEST: epoch: 5 loss: 0.880519688129425 batch: 250 accuracy:  81.050%\n",
      "TEST: epoch: 5 loss: 0.4846184253692627 batch: 300 accuracy:  80.292%\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "\n",
    "    trn_corr = 0\n",
    "    for batch, (X_train, y_train) in enumerate(train_loader):\n",
    "        y_pred = cnn_model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "\n",
    "        # How many predicted correct.\n",
    "        trn_corr += (torch.max(y_pred.data, 1)[1] == y_train).sum()\n",
    "        \n",
    "        batch += 1\n",
    "        if batch % 200 == 0:\n",
    "            print(f\"TRAIN: epoch: {epoch} loss: {loss.item()} batch: {batch} accuracy: {trn_corr.item() * 100 / (8 * batch):7.3f}%\")\n",
    "\n",
    "        # Train.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tst_corr = 0\n",
    "        for batch, (X_test, y_test) in enumerate(test_loader):\n",
    "            y_pred = cnn_model(X_test)\n",
    "            loss = criterion(y_pred, y_test)\n",
    "            # How many predicted correct.\n",
    "            tst_corr += (torch.max(y_pred.data,1)[1] == y_test).sum()\n",
    "\n",
    "            batch += 1\n",
    "            if batch % 50 == 0:\n",
    "                print(f\"TEST: epoch: {epoch} loss: {loss.item()} batch: {batch} accuracy: {tst_corr.item() * 100 / (8 * batch):7.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn_model.state_dict(), \"../../models/cats-and-dogs.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
